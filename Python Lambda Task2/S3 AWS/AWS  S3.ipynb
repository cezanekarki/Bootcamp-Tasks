{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a36f2ffe-cee8-4ab5-8988-c6b70fe85c66",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import boto3\n",
    "from io import BytesIO\n",
    "import zipfile\n",
    "import os\n",
    "\n",
    "def lambda_handler(event, context):\n",
    "    s3_client = boto3.client('s3')\n",
    "\n",
    "    source_bucket = event['Records'][0]['s3']['bucket']['name']\n",
    "    source_key = event['Records'][0]['s3']['object']['key']\n",
    "\n",
    "    response = s3_client.get_object(Bucket=source_bucket, Key=source_key)\n",
    "    compressed_data = response['Body'].read()\n",
    "    compressed_file = BytesIO(compressed_data)\n",
    "\n",
    "    with zipfile.ZipFile(compressed_file, 'r') as zip_ref:\n",
    "       \n",
    "        for file_info in zip_ref.infolist():\n",
    "            if file_info.filename.startswith('rrf/'):\n",
    "                file_name = os.path.basename(file_info.filename)  # Extract only the filename\n",
    "                zip_ref.extract(file_info, '/tmp')  # Extract the file\n",
    "\n",
    "                target_bucket = 'forzipfile'\n",
    "                target_key = f'unzipped/{file_name}'\n",
    "                s3_client.upload_file(f'/tmp/{file_info.filename}', target_bucket, target_key)\n",
    "                print(f\"File '{file_name}' from 'rrf' folder uploaded to {target_bucket}/{target_key}\")\n",
    "\n",
    "    print(\"Extraction and upload completed.\")\n",
    "\n",
    "\n",
    "def lambda_handler(event, context):\n",
    "    s3_client = boto3.client('s3')\n",
    "\n",
    "    source_bucket = event['Records'][0]['s3']['bucket']['name']\n",
    "    source_key = event['Records'][0]['s3']['object']['key']\n",
    "\n",
    "    response = s3_client.get_object(Bucket=source_bucket, Key=source_key)\n",
    "    compressed_data = response['Body'].read()\n",
    "    compressed_file = BytesIO(compressed_data)\n",
    "\n",
    "    with zipfile.ZipFile(compressed_file, 'r') as zip_ref:\n",
    "       \n",
    "        for file_info in zip_ref.infolist():\n",
    "            if file_info.filename.startswith('rrf/'):\n",
    "                file_name = os.path.basename(file_info.filename)  # Extract only the filename\n",
    "                zip_ref.extract(file_info, '/tmp')  # Extract the file\n",
    "\n",
    "                target_bucket = 'forzipfile'\n",
    "                target_key = f'unzipped/{file_name}'\n",
    "                s3_client.upload_file(f'/tmp/{file_info.filename}', target_bucket, target_key)\n",
    "                print(f\"File '{file_name}' from 'rrf' folder uploaded to {target_bucket}/{target_key}\")\n",
    "\n",
    "    print(\"Extraction and upload completed.\")\n",
    "\n",
    "def lambda_handler(event, context):\n",
    "    s3_client = boto3.client('s3')\n",
    "\n",
    "    source_bucket = event['Records'][0]['s3']['bucket']['name']\n",
    "    source_key = event['Records'][0]['s3']['object']['key']\n",
    "\n",
    "    response = s3_client.get_object(Bucket=source_bucket, Key=source_key)\n",
    "    compressed_data = response['Body'].read()\n",
    "    compressed_file = BytesIO(compressed_data)\n",
    "\n",
    "    with zipfile.ZipFile(compressed_file, 'r') as zip_ref:\n",
    "       \n",
    "        for file_info in zip_ref.infolist():\n",
    "            if file_info.filename.startswith('rrf/'):\n",
    "                file_name = os.path.basename(file_info.filename)  # Extract only the filename\n",
    "                zip_ref.extract(file_info, '/tmp')  # Extract the file\n",
    "\n",
    "                target_bucket = 'forzipfile'\n",
    "                target_key = f'unzipped/{file_name}'\n",
    "                s3_client.upload_file(f'/tmp/{file_info.filename}', target_bucket, target_key)\n",
    "                print(f\"File '{file_name}' from 'rrf' folder uploaded to {target_bucket}/{target_key}\")\n",
    "\n",
    "    print(\"Extraction and upload completed.\")"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "AWS  S3",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
