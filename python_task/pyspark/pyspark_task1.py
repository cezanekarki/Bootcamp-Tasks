# -*- coding: utf-8 -*-
"""pyspark_task.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/16BT6W5JurL3wb2svvj4bNORyvdWPoTPo

# **Pyspark-task-2024-02-12**

---


*   Load both the csv and json files and union them properly.
*   Instead of dropping the duplicates create a boolean column is_duplicate and set false to the non duplicate value and true to duplicate.
* Calculate mean salary of each department and check if salary is greater or equal to mean salary and populate the boolean value likewise.
* Calculate the mean salary of all the employee and check if salary is greater or equal to mean salary and populate with boolean value.
"""

pip install pyspark

from pyspark.sql import SparkSession

spark = SparkSession.builder.appName('Practise').getOrCreate()
spark

from google.colab import drive
drive.mount('/content/drive')

#Load the data for the csv file
df_csv = spark.read.format("csv").option("header",True).load("/content/drive/MyDrive/data/csv/batch.csv")
df_csv.printSchema()
df_csv.show()

#Load the data for json file
df_json = spark.read.format('json').load("/content/drive/MyDrive/data/json") # Loadin whole json folder
df_json.printSchema()
df_json.show()

from pyspark.sql.types import StructType,StructField,IntegerType,StringType,DateType

# Chaing the datatypes of the the columns
schema = StructType([
    StructField("id",IntegerType()),
    StructField("name",StringType()),
    StructField("dob",DateType()),
    StructField("age",IntegerType()),
    StructField("salary",IntegerType()),
    StructField("department",StringType()),
])

#Loading json with the changed schema for all the data types
df_json = spark.read.format('json').schema(schema).load("/content/drive/MyDrive/data/json")
df_json.printSchema()
df_json.show()

#Loading csv with the changed schema for all the data types
df_csv = spark.read.format("csv").schema(schema).option("header",True).load("/content/drive/MyDrive/data/csv/batch.csv")
df_csv.printSchema()
df_csv.show()

#Union operation on json and csv data
df = df_csv.union(df_json)
df.show()

from pyspark.sql import functions as F
from pyspark.sql.window import Window

duplicate = Window.partitionBy(df.columns).orderBy("id")

#Populating the boolean values for the column is_duplicate if the column are duplicated then true else false
df = df.withColumn(
    "is_duplicate",
    F.row_number().over(duplicate) > 1
)

df.show()

window = Window.partitionBy(F.col("department")).orderBy("id")

#Checking if the salary of the employee is greater or equal than the average salary
#of employee in each department and assigning true or false accordingly
df = df.withColumn(
    "department_average_greater_or_equals",
    F.col("salary")>= F.avg(F.col("salary")).over(window)
)

df.show()

#Mean salary of all the employees
mean_salary = df.select(F.avg("salary")).show()

#Checking the greater or equal salary for each employee with referenced to the average salary of all the employee
df = df.withColumn( #mean salary 73352
    "total_average_is_greater_or_equal",
    F.col("salary") >= df.agg(F.avg("salary")).head()[0]
)

df.show()