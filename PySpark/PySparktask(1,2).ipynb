{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8d4a5858-8b0d-42fb-a0ad-f43d19804511",
     "showTitle": true,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# 1.Create a new notebook.\n",
    "# load both the csv and json files. union them properly\n",
    "# Instead of dropping the duplicates, create a boolean column is_duplicate and set False to only one and True to the rest of them\n",
    "\n",
    "# 2.Calculate mean salary and check if it is greater or equal to the salary of employees in each department.\n",
    "# Calculate mean salary and check if it is greater or equal to the salary of all employees."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ff20a9b1-dfeb-4ce2-a898-15f2f4ed3e8e",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - hive</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"/?o=2085830725623723#setting/sparkui/0219-121812-a866qo7s/driver-1751641933222057365\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.3.2</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[8]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>Databricks Shell</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "\n            <div>\n                <p><b>SparkSession - hive</b></p>\n                \n        <div>\n            <p><b>SparkContext</b></p>\n\n            <p><a href=\"/?o=2085830725623723#setting/sparkui/0219-121812-a866qo7s/driver-1751641933222057365\">Spark UI</a></p>\n\n            <dl>\n              <dt>Version</dt>\n                <dd><code>v3.3.2</code></dd>\n              <dt>Master</dt>\n                <dd><code>local[8]</code></dd>\n              <dt>AppName</dt>\n                <dd><code>Databricks Shell</code></dd>\n            </dl>\n        </div>\n        \n            </div>\n        ",
       "datasetInfos": [],
       "metadata": {},
       "removedWidgets": [],
       "textData": null,
       "type": "htmlSandbox"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.getOrCreate()\n",
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "59025c9e-7942-4836-b1f3-6bff6c461510",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>path</th><th>name</th><th>size</th><th>modificationTime</th></tr></thead><tbody><tr><td>dbfs:/FileStore/tables/Drugs_package-1.csv</td><td>Drugs_package-1.csv</td><td>27234691</td><td>1707889333000</td></tr><tr><td>dbfs:/FileStore/tables/Drugs_package.csv</td><td>Drugs_package.csv</td><td>27234691</td><td>1707889300000</td></tr><tr><td>dbfs:/FileStore/tables/Drugs_product-1.csv</td><td>Drugs_product-1.csv</td><td>38743242</td><td>1707889337000</td></tr><tr><td>dbfs:/FileStore/tables/Drugs_product.csv</td><td>Drugs_product.csv</td><td>38743242</td><td>1707889319000</td></tr><tr><td>dbfs:/FileStore/tables/csv/</td><td>csv/</td><td>0</td><td>0</td></tr><tr><td>dbfs:/FileStore/tables/json/</td><td>json/</td><td>0</td><td>0</td></tr><tr><td>dbfs:/FileStore/tables/parquet/</td><td>parquet/</td><td>0</td><td>0</td></tr><tr><td>dbfs:/FileStore/tables/train/</td><td>train/</td><td>0</td><td>0</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         "dbfs:/FileStore/tables/Drugs_package-1.csv",
         "Drugs_package-1.csv",
         27234691,
         1707889333000
        ],
        [
         "dbfs:/FileStore/tables/Drugs_package.csv",
         "Drugs_package.csv",
         27234691,
         1707889300000
        ],
        [
         "dbfs:/FileStore/tables/Drugs_product-1.csv",
         "Drugs_product-1.csv",
         38743242,
         1707889337000
        ],
        [
         "dbfs:/FileStore/tables/Drugs_product.csv",
         "Drugs_product.csv",
         38743242,
         1707889319000
        ],
        [
         "dbfs:/FileStore/tables/csv/",
         "csv/",
         0,
         0
        ],
        [
         "dbfs:/FileStore/tables/json/",
         "json/",
         0,
         0
        ],
        [
         "dbfs:/FileStore/tables/parquet/",
         "parquet/",
         0,
         0
        ],
        [
         "dbfs:/FileStore/tables/train/",
         "train/",
         0,
         0
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {
        "isDbfsCommandResult": false
       },
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "path",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "name",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "size",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "modificationTime",
         "type": "\"long\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%fs ls dbfs:/FileStore/tables/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4b782b29-abe6-473a-afac-6161375852b3",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n |-- id: string (nullable = true)\n |-- name: string (nullable = true)\n |-- dob: string (nullable = true)\n |-- age: string (nullable = true)\n |-- salary: string (nullable = true)\n |-- department: string (nullable = true)\n\n"
     ]
    }
   ],
   "source": [
    "df_csv = spark.read.format(\"csv\").option(\"header\",True).load(\"dbfs:/FileStore/tables/csv/batch.csv\")\n",
    "df_csv.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e1da5963-bd4d-42fa-8481-45147c2f95b6",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.types import StructType,StructField,IntegerType, StringType,DateType\n",
    "sch = StructType([\n",
    "    StructField(\"id\",IntegerType()),\n",
    "    StructField(\"name\",StringType()),\n",
    "    StructField(\"dob\",DateType()),\n",
    "    StructField(\"age\",IntegerType()),\n",
    "    StructField(\"salary\",IntegerType()),\n",
    "    StructField(\"department\",StringType()),\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8bde5019-4f9a-4143-818d-9e6130b5dbfe",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----+----------+----+------+----------+\n| id| name|       dob| age|salary|department|\n+---+-----+----------+----+------+----------+\n|  1| John|1992-05-12|  30| 70000|        IT|\n|  2|Alice|1997-02-28|  25| 60000|        HR|\n|  3|  Bob|      null|null| 80000|        IT|\n|  4|Emily|1994-11-22|  28| 65000|   Finance|\n+---+-----+----------+----+------+----------+\n\n"
     ]
    }
   ],
   "source": [
    "df_csv = spark.read.format(\"csv\").schema(sch).option(\"header\",True).load(\"dbfs:/FileStore/tables/csv/batch.csv\")\n",
    "df_csv.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b1d23180-4ebd-4cbe-ac4e-57e5e183afad",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------+----------+----+------+----------+\n| id|  name|       dob| age|salary|department|\n+---+------+----------+----+------+----------+\n|  1|  John|1992-05-12|  30| 70000|        IT|\n|  2| Alice|1997-02-28|  25| 60000|        HR|\n|  3|   Bob|      null|null| 80000|        IT|\n|  4| Emily|1994-11-22|  28| 65000|   Finance|\n|  5| David|1981-12-18|  41| 90000|        HR|\n|  6| Susan|1989-07-05|  33| 75000|   Finance|\n|  7|  Mike|1976-03-15|  46| 95000|        IT|\n|  1|  John|1992-05-12|  30| 70000|        IT|\n|  2| Alice|1997-02-28|  25| 60000|        HR|\n|  3|   Bob|      null|null| 80000|        IT|\n|  4| Emily|1994-11-22|  28| 65000|   Finance|\n|  5| David|1981-12-18|  41| 90000|        HR|\n|  6| Susan|1989-07-05|  33| 75000|   Finance|\n|  7|  Mike|1976-03-15|  46| 95000|        IT|\n| 10|Sophie|1992-06-30|  30| 62000|   Finance|\n| 10|Sophie|1992-06-30|  30| 62000|   Finance|\n|  2| Alice|1997-02-28|  25| 90000|   Finance|\n|  2| Alice|1997-02-28|  25| 90000|   Finance|\n|  4| Emily|1994-11-22|  28| 70000|   Finance|\n|  4| Emily|1994-11-22|  28| 70000|   Finance|\n+---+------+----------+----+------+----------+\nonly showing top 20 rows\n\n"
     ]
    }
   ],
   "source": [
    "\n",
    "df_json = spark.read.format(\"json\").schema(sch).option(\"header\",True).load(\"dbfs:/FileStore/tables/json\")\n",
    "df_json.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6be4172a-04e3-4d5f-b8f1-3dd80b338c82",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------+----------+----+------+----------+\n| id|  name|       dob| age|salary|department|\n+---+------+----------+----+------+----------+\n|  1|  John|1992-05-12|  30| 70000|        IT|\n|  2| Alice|1997-02-28|  25| 60000|        HR|\n|  3|   Bob|      null|null| 80000|        IT|\n|  4| Emily|1994-11-22|  28| 65000|   Finance|\n|  1|  John|1992-05-12|  30| 70000|        IT|\n|  2| Alice|1997-02-28|  25| 60000|        HR|\n|  3|   Bob|      null|null| 80000|        IT|\n|  4| Emily|1994-11-22|  28| 65000|   Finance|\n|  5| David|1981-12-18|  41| 90000|        HR|\n|  6| Susan|1989-07-05|  33| 75000|   Finance|\n|  7|  Mike|1976-03-15|  46| 95000|        IT|\n|  1|  John|1992-05-12|  30| 70000|        IT|\n|  2| Alice|1997-02-28|  25| 60000|        HR|\n|  3|   Bob|      null|null| 80000|        IT|\n|  4| Emily|1994-11-22|  28| 65000|   Finance|\n|  5| David|1981-12-18|  41| 90000|        HR|\n|  6| Susan|1989-07-05|  33| 75000|   Finance|\n|  7|  Mike|1976-03-15|  46| 95000|        IT|\n| 10|Sophie|1992-06-30|  30| 62000|   Finance|\n| 10|Sophie|1992-06-30|  30| 62000|   Finance|\n+---+------+----------+----+------+----------+\nonly showing top 20 rows\n\n"
     ]
    }
   ],
   "source": [
    "df=df_csv.union(df_json)\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "63d7a878-deae-4c92-b704-74c582f39d72",
     "showTitle": true,
     "title": "Task 1: Finding Duplicate value"
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----+----------+----+------+----------+-----------+\n| id| name|       dob| age|salary|department|isDuplicate|\n+---+-----+----------+----+------+----------+-----------+\n|  1| John|1992-05-12|  30| 70000|        IT|       true|\n|  1| John|1992-05-12|  30| 70000|        IT|       true|\n|  1| John|1992-05-12|  30| 70000|        IT|       true|\n|  1| John|1992-05-12|  30| 70000|        IT|       true|\n|  1| John|1992-05-12|  30| 70000|        IT|       true|\n|  2|Alice|1997-02-28|  25| 60000|        HR|       true|\n|  2|Alice|1997-02-28|  25| 60000|        HR|       true|\n|  2|Alice|1997-02-28|  25| 60000|        HR|       true|\n|  2|Alice|1997-02-28|  25| 90000|   Finance|       true|\n|  2|Alice|1997-02-28|  25| 90000|   Finance|       true|\n|  3|  Bob|      null|null| 80000|        IT|       true|\n|  3|  Bob|      null|null| 80000|        IT|       true|\n|  3|  Bob|      null|null| 80000|        IT|       true|\n|  4|Emily|1994-11-22|  28| 65000|   Finance|       true|\n|  4|Emily|1994-11-22|  28| 65000|   Finance|       true|\n|  4|Emily|1994-11-22|  28| 65000|   Finance|       true|\n|  4|Emily|1994-11-22|  28| 70000|   Finance|       true|\n|  4|Emily|1994-11-22|  28| 70000|   Finance|       true|\n|  5|David|1981-12-18|  41| 90000|        HR|       true|\n|  5|David|1981-12-18|  41| 90000|        HR|       true|\n+---+-----+----------+----+------+----------+-----------+\nonly showing top 20 rows\n\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.window import Window\n",
    "from pyspark.sql.functions import col, count, avg\n",
    " \n",
    "windowSpec = Window.partitionBy([col(x) for x in df.columns])\n",
    "df = df.withColumn(\"count\", count(\"*\").over(windowSpec))\n",
    "df = df.withColumn(\"isDuplicate\", col(\"count\") > 1)\n",
    "df = df.drop(\"count\")\n",
    "df.show()\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "74b48923-0ecd-48ae-8d0b-7d5240fccb7c",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----+----------+----+------+----------+-----------+\n| id| name|       dob| age|salary|department|isDuplicate|\n+---+-----+----------+----+------+----------+-----------+\n|  1| John|1992-05-12|  30| 70000|        IT|       true|\n|  1| John|1992-05-12|  30| 70000|        IT|       true|\n|  1| John|1992-05-12|  30| 70000|        IT|       true|\n|  1| John|1992-05-12|  30| 70000|        IT|       true|\n|  1| John|1992-05-12|  30| 70000|        IT|       true|\n|  2|Alice|1997-02-28|  25| 60000|        HR|       true|\n|  2|Alice|1997-02-28|  25| 60000|        HR|       true|\n|  2|Alice|1997-02-28|  25| 60000|        HR|       true|\n|  2|Alice|1997-02-28|  25| 90000|   Finance|       true|\n|  2|Alice|1997-02-28|  25| 90000|   Finance|       true|\n|  3|  Bob|      null|null| 80000|        IT|       true|\n|  3|  Bob|      null|null| 80000|        IT|       true|\n|  3|  Bob|      null|null| 80000|        IT|       true|\n|  4|Emily|1994-11-22|  28| 65000|   Finance|       true|\n|  4|Emily|1994-11-22|  28| 65000|   Finance|       true|\n|  4|Emily|1994-11-22|  28| 65000|   Finance|       true|\n|  4|Emily|1994-11-22|  28| 70000|   Finance|       true|\n|  4|Emily|1994-11-22|  28| 70000|   Finance|       true|\n|  5|David|1981-12-18|  41| 90000|        HR|       true|\n|  5|David|1981-12-18|  41| 90000|        HR|       true|\n+---+-----+----------+----+------+----------+-----------+\nonly showing top 20 rows\n\n"
     ]
    }
   ],
   "source": [
    "df = df.orderBy(\"id\")\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "82cf8fa8-bdf1-4ca9-a623-001600ce0195",
     "showTitle": true,
     "title": "Task 2:Finding if salary greater than Mean salary of the department"
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------+----------+----+------+----------+-----------+\n| id|  name|       dob| age|salary|department|isDuplicate|\n+---+------+----------+----+------+----------+-----------+\n|  1|  John|1992-05-12|  30| 70000|        IT|       true|\n|  2| Alice|1997-02-28|  25| 60000|        HR|       true|\n|  2| Alice|1997-02-28|  25| 90000|   Finance|       true|\n|  3|   Bob|      null|null| 80000|        IT|       true|\n|  4| Emily|1994-11-22|  28| 65000|   Finance|       true|\n|  4| Emily|1994-11-22|  28| 70000|   Finance|       true|\n|  5| David|1981-12-18|  41| 90000|        HR|       true|\n|  6| Susan|1989-07-05|  33| 75000|   Finance|       true|\n|  7|  Mike|1976-03-15|  46| 95000|        IT|       true|\n|  8|  Lisa|1995-08-20|  27| 58000|        HR|       true|\n|  9| James|1983-10-14|  39| 87000|        IT|       true|\n| 10|Sophie|1992-06-30|  30| 62000|   Finance|       true|\n+---+------+----------+----+------+----------+-----------+\n\n"
     ]
    }
   ],
   "source": [
    "df = df.dropDuplicates()\n",
    "df.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "73802c15-19cc-45b2-8323-12a41c6827f5",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------+----------+----+------+----------+-----------+-----------------+\n| id|  name|       dob| age|salary|department|isDuplicate|      Mean salary|\n+---+------+----------+----+------+----------+-----------+-----------------+\n|  2| Alice|1997-02-28|  25| 90000|   Finance|       true|          72400.0|\n|  4| Emily|1994-11-22|  28| 65000|   Finance|       true|          72400.0|\n|  4| Emily|1994-11-22|  28| 70000|   Finance|       true|          72400.0|\n|  6| Susan|1989-07-05|  33| 75000|   Finance|       true|          72400.0|\n| 10|Sophie|1992-06-30|  30| 62000|   Finance|       true|          72400.0|\n|  2| Alice|1997-02-28|  25| 60000|        HR|       true|69333.33333333333|\n|  5| David|1981-12-18|  41| 90000|        HR|       true|69333.33333333333|\n|  8|  Lisa|1995-08-20|  27| 58000|        HR|       true|69333.33333333333|\n|  1|  John|1992-05-12|  30| 70000|        IT|       true|          83000.0|\n|  3|   Bob|      null|null| 80000|        IT|       true|          83000.0|\n|  7|  Mike|1976-03-15|  46| 95000|        IT|       true|          83000.0|\n|  9| James|1983-10-14|  39| 87000|        IT|       true|          83000.0|\n+---+------+----------+----+------+----------+-----------+-----------------+\n\n"
     ]
    }
   ],
   "source": [
    "windowSpec = Window.partitionBy(df.department)\n",
    "df = df.withColumn(\"Mean salary\", avg(\"salary\").over(windowSpec))\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "72ed53b0-743d-4ee1-8b89-ce4661686c03",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------+----------+----+------+----------+-----------+-----------------+----------------------------------+\n| id|  name|       dob| age|salary|department|isDuplicate|      Mean salary|Is Salary greater than mean Salary|\n+---+------+----------+----+------+----------+-----------+-----------------+----------------------------------+\n|  1|  John|1992-05-12|  30| 70000|        IT|       true|          83000.0|                             false|\n|  2| Alice|1997-02-28|  25| 90000|   Finance|       true|          72400.0|                              true|\n|  2| Alice|1997-02-28|  25| 60000|        HR|       true|69333.33333333333|                             false|\n|  3|   Bob|      null|null| 80000|        IT|       true|          83000.0|                             false|\n|  4| Emily|1994-11-22|  28| 65000|   Finance|       true|          72400.0|                             false|\n|  4| Emily|1994-11-22|  28| 70000|   Finance|       true|          72400.0|                             false|\n|  5| David|1981-12-18|  41| 90000|        HR|       true|69333.33333333333|                              true|\n|  6| Susan|1989-07-05|  33| 75000|   Finance|       true|          72400.0|                              true|\n|  7|  Mike|1976-03-15|  46| 95000|        IT|       true|          83000.0|                              true|\n|  8|  Lisa|1995-08-20|  27| 58000|        HR|       true|69333.33333333333|                             false|\n|  9| James|1983-10-14|  39| 87000|        IT|       true|          83000.0|                              true|\n| 10|Sophie|1992-06-30|  30| 62000|   Finance|       true|          72400.0|                             false|\n+---+------+----------+----+------+----------+-----------+-----------------+----------------------------------+\n\n"
     ]
    }
   ],
   "source": [
    "df = df.withColumn(\n",
    "    \"Is Salary greater than mean Salary\",\n",
    "    col(\"Mean salary\") < col(\"salary\")\n",
    ").orderBy(\"id\")\n",
    "df.show()"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 526057676423765,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "PySparktask(1,2)",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
