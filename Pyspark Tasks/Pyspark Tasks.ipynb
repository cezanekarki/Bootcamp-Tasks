{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "643f0044-ebe0-482c-adab-541b182b7642",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "Create a new notebook Load both csv and json file. Union them properly.\n",
    "Instead of dropping the duplicates, create a boolean column is_duplicate and set False to only one row and set False to only one row and True to the rest of them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4c2f5ec7-1da0-47a4-8ee7-8b5fa946e258",
     "showTitle": false,
     "title": "Create a new notebook Load both csv and json file. Union them properly. Instead of dropping the duplicates, create a boolean column is_duplicate and set False to only one row and set False to only one row and True to the rest of them"
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - hive</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"/?o=5606541341624162#setting/sparkui/0221-070315-ol6iu34m/driver-5113252644529607458\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.3.2</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[8]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>Databricks Shell</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "\n            <div>\n                <p><b>SparkSession - hive</b></p>\n                \n        <div>\n            <p><b>SparkContext</b></p>\n\n            <p><a href=\"/?o=5606541341624162#setting/sparkui/0221-070315-ol6iu34m/driver-5113252644529607458\">Spark UI</a></p>\n\n            <dl>\n              <dt>Version</dt>\n                <dd><code>v3.3.2</code></dd>\n              <dt>Master</dt>\n                <dd><code>local[8]</code></dd>\n              <dt>AppName</dt>\n                <dd><code>Databricks Shell</code></dd>\n            </dl>\n        </div>\n        \n            </div>\n        ",
       "datasetInfos": [],
       "metadata": {},
       "removedWidgets": [],
       "textData": null,
       "type": "htmlSandbox"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.getOrCreate()\n",
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1e3c57a0-8cc3-4849-945c-e6da13e8d649",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_csv= spark.read.format(\"csv\").load(\"dbfs:/FileStore/tables/csv/batch.csv\")\n",
    "df_json= spark.read.format(\"json\").load(\"dbfs:///FileStore/tables/json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6daefc0f-2bd8-495e-94ae-3665d4a871be",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----+----------+----+------+----------+\n|_c0|  _c1|       _c2| _c3|   _c4|       _c5|\n+---+-----+----------+----+------+----------+\n| id| name|       dob| age|salary|department|\n|  1| John|1992-05-12|  30| 70000|        IT|\n|  2|Alice|1997-02-28|  25| 60000|        HR|\n|  3|  Bob|      null|null| 80000|        IT|\n|  4|Emily|1994-11-22|  28| 65000|   Finance|\n+---+-----+----------+----+------+----------+\n\n"
     ]
    }
   ],
   "source": [
    "df_csv.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c7cfcf89-46fb-4288-afb3-e3ad6f693707",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+----------+----------+---+------+------+\n| age|department|       dob| id|  name|salary|\n+----+----------+----------+---+------+------+\n|  30|        IT|1992-05-12|  1|  John| 70000|\n|  25|        HR|1997-02-28|  2| Alice| 60000|\n|null|        IT|      null|  3|   Bob| 80000|\n|  28|   Finance|1994-11-22|  4| Emily| 65000|\n|  41|        HR|1981-12-18|  5| David| 90000|\n|  33|   Finance|1989-07-05|  6| Susan| 75000|\n|  46|        IT|1976-03-15|  7|  Mike| 95000|\n|  30|   Finance|1992-06-30| 10|Sophie| 62000|\n|  25|   Finance|1997-02-28|  2| Alice| 90000|\n|  28|   Finance|1994-11-22|  4| Emily| 70000|\n|  39|        IT|1983-10-14|  9| James| 87000|\n|  30|        IT|1992-05-12|  1|  John| 70000|\n|  27|        HR|1995-08-20|  8|  Lisa| 58000|\n+----+----------+----------+---+------+------+\n\n"
     ]
    }
   ],
   "source": [
    "df_json.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "022ab665-f649-4e55-b2c8-7493f4ca1d90",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.types  import StructType, StructField, IntegerType,StringType,DateType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f9d97d7e-300d-446e-8c6f-6b62d09daa9d",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "schema =StructType([\n",
    "    StructField(\"id\",IntegerType()),\n",
    "    StructField(\"name\",StringType()),\n",
    "    StructField(\"dob\",DateType()),\n",
    "    StructField(\"age\",IntegerType()),\n",
    "    StructField(\"salary\",IntegerType()),\n",
    "    StructField(\"department\",StringType()),\n",
    " \n",
    "])\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5163a2e9-b7f6-4dd1-a9a4-c2dc13e2ce31",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_csv=spark.read.format(\"csv\").schema(schema).option(\"header\",True).load(\"dbfs:////FileStore/tables/csv/batch.csv\")\n",
    "df_json = spark.read.format(\"json\").schema(schema).option(\"header\",True).load(\"dbfs:///FileStore/tables/json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "60539a9f-b9f3-4ea4-afe5-7a7248dd42a2",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>id</th><th>name</th><th>dob</th><th>age</th><th>salary</th><th>department</th></tr></thead><tbody><tr><td>1</td><td>John</td><td>1992-05-12</td><td>30</td><td>70000</td><td>IT</td></tr><tr><td>2</td><td>Alice</td><td>1997-02-28</td><td>25</td><td>60000</td><td>HR</td></tr><tr><td>3</td><td>Bob</td><td>null</td><td>null</td><td>80000</td><td>IT</td></tr><tr><td>4</td><td>Emily</td><td>1994-11-22</td><td>28</td><td>65000</td><td>Finance</td></tr><tr><td>1</td><td>John</td><td>1992-05-12</td><td>30</td><td>70000</td><td>IT</td></tr><tr><td>2</td><td>Alice</td><td>1997-02-28</td><td>25</td><td>60000</td><td>HR</td></tr><tr><td>3</td><td>Bob</td><td>null</td><td>null</td><td>80000</td><td>IT</td></tr><tr><td>4</td><td>Emily</td><td>1994-11-22</td><td>28</td><td>65000</td><td>Finance</td></tr><tr><td>5</td><td>David</td><td>1981-12-18</td><td>41</td><td>90000</td><td>HR</td></tr><tr><td>6</td><td>Susan</td><td>1989-07-05</td><td>33</td><td>75000</td><td>Finance</td></tr><tr><td>7</td><td>Mike</td><td>1976-03-15</td><td>46</td><td>95000</td><td>IT</td></tr><tr><td>10</td><td>Sophie</td><td>1992-06-30</td><td>30</td><td>62000</td><td>Finance</td></tr><tr><td>2</td><td>Alice</td><td>1997-02-28</td><td>25</td><td>90000</td><td>Finance</td></tr><tr><td>4</td><td>Emily</td><td>1994-11-22</td><td>28</td><td>70000</td><td>Finance</td></tr><tr><td>9</td><td>James</td><td>1983-10-14</td><td>39</td><td>87000</td><td>IT</td></tr><tr><td>1</td><td>John</td><td>1992-05-12</td><td>30</td><td>70000</td><td>IT</td></tr><tr><td>8</td><td>Lisa</td><td>1995-08-20</td><td>27</td><td>58000</td><td>HR</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         1,
         "John",
         "1992-05-12",
         30,
         70000,
         "IT"
        ],
        [
         2,
         "Alice",
         "1997-02-28",
         25,
         60000,
         "HR"
        ],
        [
         3,
         "Bob",
         null,
         null,
         80000,
         "IT"
        ],
        [
         4,
         "Emily",
         "1994-11-22",
         28,
         65000,
         "Finance"
        ],
        [
         1,
         "John",
         "1992-05-12",
         30,
         70000,
         "IT"
        ],
        [
         2,
         "Alice",
         "1997-02-28",
         25,
         60000,
         "HR"
        ],
        [
         3,
         "Bob",
         null,
         null,
         80000,
         "IT"
        ],
        [
         4,
         "Emily",
         "1994-11-22",
         28,
         65000,
         "Finance"
        ],
        [
         5,
         "David",
         "1981-12-18",
         41,
         90000,
         "HR"
        ],
        [
         6,
         "Susan",
         "1989-07-05",
         33,
         75000,
         "Finance"
        ],
        [
         7,
         "Mike",
         "1976-03-15",
         46,
         95000,
         "IT"
        ],
        [
         10,
         "Sophie",
         "1992-06-30",
         30,
         62000,
         "Finance"
        ],
        [
         2,
         "Alice",
         "1997-02-28",
         25,
         90000,
         "Finance"
        ],
        [
         4,
         "Emily",
         "1994-11-22",
         28,
         70000,
         "Finance"
        ],
        [
         9,
         "James",
         "1983-10-14",
         39,
         87000,
         "IT"
        ],
        [
         1,
         "John",
         "1992-05-12",
         30,
         70000,
         "IT"
        ],
        [
         8,
         "Lisa",
         "1995-08-20",
         27,
         58000,
         "HR"
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {},
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "id",
         "type": "\"integer\""
        },
        {
         "metadata": "{}",
         "name": "name",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "dob",
         "type": "\"date\""
        },
        {
         "metadata": "{}",
         "name": "age",
         "type": "\"integer\""
        },
        {
         "metadata": "{}",
         "name": "salary",
         "type": "\"integer\""
        },
        {
         "metadata": "{}",
         "name": "department",
         "type": "\"string\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Task : Load both csv and json union them from pyspark.sql \n",
    "\n",
    "from pyspark.sql.window import Window\n",
    "df=df_csv.union(df_json) \n",
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "596dfacf-bacc-4149-9fbf-046e32dab288",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------+----------+----+------+----------+------------+\n| id|  name|       dob| age|salary|department|is_duplicate|\n+---+------+----------+----+------+----------+------------+\n|  1|  John|1992-05-12|  30| 70000|        IT|       false|\n|  1|  John|1992-05-12|  30| 70000|        IT|        true|\n|  1|  John|1992-05-12|  30| 70000|        IT|        true|\n|  2| Alice|1997-02-28|  25| 60000|        HR|       false|\n|  2| Alice|1997-02-28|  25| 60000|        HR|        true|\n|  2| Alice|1997-02-28|  25| 90000|   Finance|       false|\n|  3|   Bob|      null|null| 80000|        IT|       false|\n|  3|   Bob|      null|null| 80000|        IT|        true|\n|  4| Emily|1994-11-22|  28| 65000|   Finance|       false|\n|  4| Emily|1994-11-22|  28| 65000|   Finance|        true|\n|  4| Emily|1994-11-22|  28| 70000|   Finance|       false|\n|  5| David|1981-12-18|  41| 90000|        HR|       false|\n|  6| Susan|1989-07-05|  33| 75000|   Finance|       false|\n|  7|  Mike|1976-03-15|  46| 95000|        IT|       false|\n|  8|  Lisa|1995-08-20|  27| 58000|        HR|       false|\n|  9| James|1983-10-14|  39| 87000|        IT|       false|\n| 10|Sophie|1992-06-30|  30| 62000|   Finance|       false|\n+---+------+----------+----+------+----------+------------+\n\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import functions as F\n",
    "df.withColumn( \"is_duplicate\", (F.row_number().over(Window.partitionBy(df.columns).orderBy(\"id\"))) > 1 ).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2fc5b9f6-da63-4d95-a40d-6bcd2136a2d7",
     "showTitle": true,
     "title": "Next Method"
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------+----------+----+------+----------+------------+\n| id|  name|       dob| age|salary|department|is_duplicate|\n+---+------+----------+----+------+----------+------------+\n|  1|  John|1992-05-12|  30| 70000|        IT|       false|\n|  1|  John|1992-05-12|  30| 70000|        IT|        true|\n|  1|  John|1992-05-12|  30| 70000|        IT|        true|\n|  2| Alice|1997-02-28|  25| 60000|        HR|       false|\n|  2| Alice|1997-02-28|  25| 60000|        HR|        true|\n|  2| Alice|1997-02-28|  25| 90000|   Finance|       false|\n|  3|   Bob|      null|null| 80000|        IT|       false|\n|  3|   Bob|      null|null| 80000|        IT|        true|\n|  4| Emily|1994-11-22|  28| 65000|   Finance|       false|\n|  4| Emily|1994-11-22|  28| 65000|   Finance|        true|\n|  4| Emily|1994-11-22|  28| 70000|   Finance|       false|\n|  5| David|1981-12-18|  41| 90000|        HR|       false|\n|  6| Susan|1989-07-05|  33| 75000|   Finance|       false|\n|  7|  Mike|1976-03-15|  46| 95000|        IT|       false|\n|  8|  Lisa|1995-08-20|  27| 58000|        HR|       false|\n|  9| James|1983-10-14|  39| 87000|        IT|       false|\n| 10|Sophie|1992-06-30|  30| 62000|   Finance|       false|\n+---+------+----------+----+------+----------+------------+\n\n"
     ]
    }
   ],
   "source": [
    "window =Window.partitionBy(*df.columns).orderBy(\"id\")   \n",
    "df.withColumn(\"is_duplicate\", \n",
    "    F.row_number().over(window) != 1,      \n",
    ").show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "bf3b665d-4ba9-4562-ba2d-3e299f6c6ab8",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "Tasks:\n",
    "Calculate mean salary and check if it is greater or equal to the salary of employees in each department.\n",
    "\n",
    "Calculate mean salary and check if it is greater or equal to the salary of all employees."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c969d3d9-b3cd-4560-9043-02f9391260f6",
     "showTitle": true,
     "title": "Task 1"
    }
   },
   "outputs": [],
   "source": [
    "department_window =Window.partitionBy(\"department\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7d4442e6-3a2a-45c1-b1ca-7f1f842d7373",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------+----------+----+------+----------+-----------------+-----------------+\n| id|  name|       dob| age|salary|department|      mean_salary|is_salary_greater|\n+---+------+----------+----+------+----------+-----------------+-----------------+\n|  4| Emily|1994-11-22|  28| 65000|   Finance|71166.66666666667|            false|\n|  4| Emily|1994-11-22|  28| 65000|   Finance|71166.66666666667|            false|\n|  6| Susan|1989-07-05|  33| 75000|   Finance|71166.66666666667|             true|\n| 10|Sophie|1992-06-30|  30| 62000|   Finance|71166.66666666667|            false|\n|  2| Alice|1997-02-28|  25| 90000|   Finance|71166.66666666667|             true|\n|  4| Emily|1994-11-22|  28| 70000|   Finance|71166.66666666667|            false|\n|  2| Alice|1997-02-28|  25| 60000|        HR|          67000.0|            false|\n|  2| Alice|1997-02-28|  25| 60000|        HR|          67000.0|            false|\n|  5| David|1981-12-18|  41| 90000|        HR|          67000.0|             true|\n|  8|  Lisa|1995-08-20|  27| 58000|        HR|          67000.0|            false|\n|  1|  John|1992-05-12|  30| 70000|        IT|78857.14285714286|            false|\n|  3|   Bob|      null|null| 80000|        IT|78857.14285714286|             true|\n|  1|  John|1992-05-12|  30| 70000|        IT|78857.14285714286|            false|\n|  3|   Bob|      null|null| 80000|        IT|78857.14285714286|             true|\n|  7|  Mike|1976-03-15|  46| 95000|        IT|78857.14285714286|             true|\n|  9| James|1983-10-14|  39| 87000|        IT|78857.14285714286|             true|\n|  1|  John|1992-05-12|  30| 70000|        IT|78857.14285714286|            false|\n+---+------+----------+----+------+----------+-----------------+-----------------+\n\n"
     ]
    }
   ],
   "source": [
    "df.withColumns(\n",
    "    {\n",
    "        \"mean_salary\":F.mean(\"salary\").over(department_window),\n",
    "        \"is_salary_greater\":F.col(\"salary\") >= F.col(\"mean_salary\"),\n",
    "    }\n",
    ").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a5f5ea4b-d502-4f6c-bf3c-b6173e5dcf2d",
     "showTitle": true,
     "title": "Next method"
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------+----------+----+------+----------+-----------------+-----------------+\n| id|  name|       dob| age|salary|department|      mean_salary|above_mean_salary|\n+---+------+----------+----+------+----------+-----------------+-----------------+\n|  4| Emily|1994-11-22|  28| 65000|   Finance|71166.66666666667|            false|\n|  4| Emily|1994-11-22|  28| 65000|   Finance|71166.66666666667|            false|\n|  6| Susan|1989-07-05|  33| 75000|   Finance|71166.66666666667|             true|\n| 10|Sophie|1992-06-30|  30| 62000|   Finance|71166.66666666667|            false|\n|  2| Alice|1997-02-28|  25| 90000|   Finance|71166.66666666667|             true|\n|  4| Emily|1994-11-22|  28| 70000|   Finance|71166.66666666667|            false|\n|  2| Alice|1997-02-28|  25| 60000|        HR|          67000.0|            false|\n|  2| Alice|1997-02-28|  25| 60000|        HR|          67000.0|            false|\n|  5| David|1981-12-18|  41| 90000|        HR|          67000.0|             true|\n|  8|  Lisa|1995-08-20|  27| 58000|        HR|          67000.0|            false|\n|  1|  John|1992-05-12|  30| 70000|        IT|78857.14285714286|            false|\n|  3|   Bob|      null|null| 80000|        IT|78857.14285714286|             true|\n|  1|  John|1992-05-12|  30| 70000|        IT|78857.14285714286|            false|\n|  3|   Bob|      null|null| 80000|        IT|78857.14285714286|             true|\n|  7|  Mike|1976-03-15|  46| 95000|        IT|78857.14285714286|             true|\n|  9| James|1983-10-14|  39| 87000|        IT|78857.14285714286|             true|\n|  1|  John|1992-05-12|  30| 70000|        IT|78857.14285714286|            false|\n+---+------+----------+----+------+----------+-----------------+-----------------+\n\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql import Window\n",
    "\n",
    "window_spec = Window.partitionBy(\"department\")\n",
    "\n",
    "result_df = df.withColumn(\"mean_salary\", F.mean(\"salary\").over(window_spec)) \\\n",
    "              .withColumn(\"above_mean_salary\", F.col(\"salary\") >= F.mean(\"salary\").over(window_spec))\n",
    "\n",
    "result_df.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "abe2634f-8496-4f89-b7e7-61530c375994",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------+----------+----+------+----------+----------------------+\n| id|  name|       dob| age|salary|department|mean_salary_department|\n+---+------+----------+----+------+----------+----------------------+\n|  4| Emily|1994-11-22|  28| 65000|   Finance|                 false|\n|  4| Emily|1994-11-22|  28| 65000|   Finance|                 false|\n|  6| Susan|1989-07-05|  33| 75000|   Finance|                  true|\n| 10|Sophie|1992-06-30|  30| 62000|   Finance|                 false|\n|  2| Alice|1997-02-28|  25| 90000|   Finance|                  true|\n|  4| Emily|1994-11-22|  28| 70000|   Finance|                 false|\n|  2| Alice|1997-02-28|  25| 60000|        HR|                 false|\n|  2| Alice|1997-02-28|  25| 60000|        HR|                 false|\n|  5| David|1981-12-18|  41| 90000|        HR|                  true|\n|  8|  Lisa|1995-08-20|  27| 58000|        HR|                 false|\n|  1|  John|1992-05-12|  30| 70000|        IT|                 false|\n|  3|   Bob|      null|null| 80000|        IT|                  true|\n|  1|  John|1992-05-12|  30| 70000|        IT|                 false|\n|  3|   Bob|      null|null| 80000|        IT|                  true|\n|  7|  Mike|1976-03-15|  46| 95000|        IT|                  true|\n|  9| James|1983-10-14|  39| 87000|        IT|                  true|\n|  1|  John|1992-05-12|  30| 70000|        IT|                 false|\n+---+------+----------+----+------+----------+----------------------+\n\n"
     ]
    }
   ],
   "source": [
    "window_spec = Window.partitionBy(\"department\")\n",
    "\n",
    "df.withColumn(\n",
    "     \"mean_salary_department\",\n",
    "     F.col(\"salary\") >= F.mean(\"salary\").over(window_spec)\n",
    " ).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e004f8d4-ea31-43cb-ba1c-995c6f1716c2",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "average_salary_by_department = df.groupBy(\"department\").agg(\n",
    "    F.avg(\"salary\").alias(\"average_salary\")\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d40ac478-0dad-447b-a771-c5cc6836d77f",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----------------+\n|department|   average_salary|\n+----------+-----------------+\n|        HR|          67000.0|\n|   Finance|71166.66666666667|\n|        IT|78857.14285714286|\n+----------+-----------------+\n\n"
     ]
    }
   ],
   "source": [
    "average_salary_by_department.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5f8ba3e1-4cea-4427-9bf0-af4e7bde9611",
     "showTitle": true,
     "title": " Task 2 :Calculate mean salary and check if it is greater or equal to the salary of all employees "
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------+----------+----+------+----------+-----------------+--------------------+\n| id|  name|       dob| age|salary|department|             mean|is_salary_above_mean|\n+---+------+----------+----+------+----------+-----------------+--------------------+\n|  1|  John|1992-05-12|  30| 70000|        IT|73352.94117647059|               false|\n|  2| Alice|1997-02-28|  25| 60000|        HR|73352.94117647059|               false|\n|  3|   Bob|      null|null| 80000|        IT|73352.94117647059|                true|\n|  4| Emily|1994-11-22|  28| 65000|   Finance|73352.94117647059|               false|\n|  1|  John|1992-05-12|  30| 70000|        IT|73352.94117647059|               false|\n|  2| Alice|1997-02-28|  25| 60000|        HR|73352.94117647059|               false|\n|  3|   Bob|      null|null| 80000|        IT|73352.94117647059|                true|\n|  4| Emily|1994-11-22|  28| 65000|   Finance|73352.94117647059|               false|\n|  5| David|1981-12-18|  41| 90000|        HR|73352.94117647059|                true|\n|  6| Susan|1989-07-05|  33| 75000|   Finance|73352.94117647059|                true|\n|  7|  Mike|1976-03-15|  46| 95000|        IT|73352.94117647059|                true|\n| 10|Sophie|1992-06-30|  30| 62000|   Finance|73352.94117647059|               false|\n|  2| Alice|1997-02-28|  25| 90000|   Finance|73352.94117647059|                true|\n|  4| Emily|1994-11-22|  28| 70000|   Finance|73352.94117647059|               false|\n|  9| James|1983-10-14|  39| 87000|        IT|73352.94117647059|                true|\n|  1|  John|1992-05-12|  30| 70000|        IT|73352.94117647059|               false|\n|  8|  Lisa|1995-08-20|  27| 58000|        HR|73352.94117647059|               false|\n+---+------+----------+----+------+----------+-----------------+--------------------+\n\n"
     ]
    }
   ],
   "source": [
    "\n",
    "window_spec =Window.partitionBy()\n",
    "\n",
    "df.withColumns(\n",
    "    {\n",
    "        \"mean\": F.mean(\"salary\").over(window_spec),\n",
    "        \"is_salary_above_mean\":\n",
    "        F.col(\"salary\")>=F.mean(\"salary\").over(window_spec)\n",
    "    }\n",
    ").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8991aa3a-dddf-4f0f-9c49-eb682e401b01",
     "showTitle": true,
     "title": "Next method"
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------+----------+----+------+----------+--------------------+\n| id|  name|       dob| age|salary|department|is_salary_above_mean|\n+---+------+----------+----+------+----------+--------------------+\n|  1|  John|1992-05-12|  30| 70000|        IT|               false|\n|  2| Alice|1997-02-28|  25| 60000|        HR|               false|\n|  3|   Bob|      null|null| 80000|        IT|                true|\n|  4| Emily|1994-11-22|  28| 65000|   Finance|               false|\n|  1|  John|1992-05-12|  30| 70000|        IT|               false|\n|  2| Alice|1997-02-28|  25| 60000|        HR|               false|\n|  3|   Bob|      null|null| 80000|        IT|                true|\n|  4| Emily|1994-11-22|  28| 65000|   Finance|               false|\n|  5| David|1981-12-18|  41| 90000|        HR|                true|\n|  6| Susan|1989-07-05|  33| 75000|   Finance|                true|\n|  7|  Mike|1976-03-15|  46| 95000|        IT|                true|\n| 10|Sophie|1992-06-30|  30| 62000|   Finance|               false|\n|  2| Alice|1997-02-28|  25| 90000|   Finance|                true|\n|  4| Emily|1994-11-22|  28| 70000|   Finance|               false|\n|  9| James|1983-10-14|  39| 87000|        IT|                true|\n|  1|  John|1992-05-12|  30| 70000|        IT|               false|\n|  8|  Lisa|1995-08-20|  27| 58000|        HR|               false|\n+---+------+----------+----+------+----------+--------------------+\n\n"
     ]
    }
   ],
   "source": [
    "window_spec = Window.partitionBy()\n",
    "window_spec = Window.orderBy()\n",
    "window_spec = Window.partitionBy().orderBy()\n",
    "\n",
    "df.withColumn(\n",
    "    \"is_salary_above_mean\",\n",
    "    (\n",
    "        F.col(\"salary\") >= F.mean(\"salary\").over(window_spec)\n",
    "    )\n",
    ").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e63fd662-a5a2-41f1-8fe9-ecfc92c008fd",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Pyspark Tasks",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
